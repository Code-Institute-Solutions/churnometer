{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python",
      "version": "3.8.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "625c31d6b4db3d7e7e2853cc30dc2062e1cda684f3e49d5f899ae496ae755fe0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering Notebook"
      ],
      "metadata": {
        "id": "0aStgWSO0E0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objectives\n",
        "\n",
        "*   Engineer features for Classification, Regression and Cluster models\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/datasets/cleaned/TrainSet.csv\n",
        "* inputs/datasets/cleaned/TestSet.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* generate a list with variables to engineer\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "\n",
        "\n",
        "* Feature Engineering Transformers\n",
        "  * Ordinal categorical encoding: `['gender', 'Partner', Dependents', 'PhoneService','MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup','DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies','Contract', 'PaperlessBilling', 'PaymentMethod']`\n",
        "  * Smart Correlation Selection: `['OnlineSecurity', 'DeviceProtection', 'TechSupport']`\n",
        "  \n"
      ],
      "metadata": {
        "id": "1eLEkw5O0ECa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "9uWZXH9LwoQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Change working directory"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to make the parent of current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confirm the new current directory"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Cleaned Data"
      ],
      "metadata": {
        "id": "-mavJ8DibrcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Set"
      ],
      "metadata": {
        "id": "j6h-QeuCa2_U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pandas as pd\n",
        "train_set_path = \"outputs/datasets/cleaned/TrainSetCleaned.csv\"\n",
        "TrainSet = pd.read_csv(train_set_path)\n",
        "TrainSet.info()"
      ],
      "outputs": [],
      "metadata": {
        "id": "C2ELZj83tF1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Set"
      ],
      "metadata": {
        "id": "NNJOqym1a38e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_set_path = 'outputs/datasets/cleaned/TestSetCleaned.csv'\n",
        "TestSet = pd.read_csv(test_set_path)\n",
        "TestSet.info()"
      ],
      "outputs": [],
      "metadata": {
        "id": "L-WRjItbiOs6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas Profiling"
      ],
      "metadata": {
        "id": "Iue5e5GJ_vZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In feature engineering, you are interested to evaluate which potential transformation you could do in your variables\n",
        "* Take your notes in your separate spreadsheet"
      ],
      "metadata": {
        "id": "edx7E2Yr4sZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Considerations**\n",
        "\n",
        "* At this stage, there are no missing data in your Train and Test sets.\n",
        "\n",
        "\n",
        "Now you are looking to engineer (**to transform**), your variables, so the Machine Learning model will better learn the relationships among the variables (features and labels).\n",
        "  * Machine Learning models learn better when the distribution is normal. To engineer that, you can use transformers in packages like feature-engine or sklearn.\n",
        "  * You can also use your business acumen and technical expertise to create new variables. For example, imagine if your dataset is about your orange juice company operation. There is a variable called \"revenue\" and other called \"volume\", you divide revenue by volume to know how much money you make per liter of manufactured juice\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "pandas_report = ProfileReport(df=TrainSet, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ],
      "outputs": [],
      "metadata": {
        "id": "oyi3gi2-_q1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation and PPS Analysis"
      ],
      "metadata": {
        "id": "LvwabO0JsmYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We don’t expect major changes compared to data cleaning notebook, since the only data difference is the removal of “customerID” and “TotalCharges”, so correlation levels and PPS will essentially be the same"
      ],
      "metadata": {
        "id": "qufL2HWrF8ig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "_ZsS4AdFjUYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom function"
      ],
      "metadata": {
        "id": "GqEHqNwyrucq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We studied this custom function on feature-engine lesson. That will help you on the feature engineering process\n",
        "* Don't worry if you don't understand the full code at first, it is expected to take some time to absorb the use case.\n",
        "* At this moment, what matters is to understand the function objective and how you can use it"
      ],
      "metadata": {
        "id": "ZuEsBAljDsLO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from feature_engine import transformation as vt\n",
        "from feature_engine.outliers import Winsorizer\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "sns.set(style=\"whitegrid\")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "\n",
        "def FeatureEngineeringAnalysis(df,analysis_type=None):\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  - used for quick feature engineering on numerical and categorical variables\n",
        "  to decide which transformation can better transform the distribution shape \n",
        "  - Once transformed, use a reporting tool, like pandas-profiling, to evaluate distributions\n",
        "\n",
        "  \"\"\"\n",
        "  check_missing_values(df)\n",
        "  allowed_types= ['numerical', 'ordinal_encoder',  'outlier_winsorizer']\n",
        "  check_user_entry_on_analysis_type(analysis_type, allowed_types)\n",
        "  list_column_transformers = define_list_column_transformers(analysis_type)\n",
        "  \n",
        "  \n",
        "  # Loop in each variable and engineer the data according to the analysis type\n",
        "  df_feat_eng = pd.DataFrame([])\n",
        "  for column in df.columns:\n",
        "    # create additional columns (column_method) to apply the methods\n",
        "    df_feat_eng = pd.concat([df_feat_eng, df[column]], axis=1)\n",
        "    for method in list_column_transformers:\n",
        "      df_feat_eng[f\"{column}_{method}\"] = df[column]\n",
        "      \n",
        "    # Apply transformers in respectives column_transformers\n",
        "    df_feat_eng,list_applied_transformers = apply_transformers(analysis_type, df_feat_eng, column)\n",
        "\n",
        "    # For each variable, assess how the transformations perform\n",
        "    transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng)\n",
        "\n",
        "  return df_feat_eng\n",
        "\n",
        "\n",
        "def check_user_entry_on_analysis_type(analysis_type, allowed_types):\n",
        "  ### Check analyis type\n",
        "  if analysis_type == None:\n",
        "    raise SystemExit(f\"You should pass analysis_type parameter as one of the following options: {allowed_types}\")\n",
        "  if analysis_type not in allowed_types:\n",
        "      raise SystemExit(f\"analysis_type argument should be one of these options: {allowed_types}\")\n",
        "\n",
        "def check_missing_values(df):\n",
        "  if df.isna().sum().sum() != 0:\n",
        "    raise SystemExit(\n",
        "        f\"There is missing value in your dataset. Please handle that before getting into feature engineering.\")\n",
        "\n",
        "\n",
        "\n",
        "def define_list_column_transformers(analysis_type):\n",
        "  ### Set suffix colummns acording to analysis_type\n",
        "  if analysis_type=='numerical':\n",
        "    list_column_transformers = [\"log_e\",\"log_10\",\"reciprocal\", \"power\",\"box_cox\",\"yeo_johnson\"]\n",
        "  \n",
        "  elif analysis_type=='ordinal_encoder':\n",
        "    list_column_transformers = [\"ordinal_encoder\"]\n",
        "\n",
        "  elif analysis_type=='outlier_winsorizer':\n",
        "    list_column_transformers = ['iqr']\n",
        "\n",
        "  return list_column_transformers\n",
        "\n",
        "\n",
        "\n",
        "def apply_transformers(analysis_type, df_feat_eng, column):\n",
        "\n",
        "\n",
        "  for col in df_feat_eng.select_dtypes(include='category').columns:\n",
        "    df_feat_eng[col] = df_feat_eng[col].astype('object')\n",
        "\n",
        "\n",
        "  if analysis_type=='numerical':\n",
        "    df_feat_eng,list_applied_transformers = FeatEngineering_Numerical(df_feat_eng,column)\n",
        "  \n",
        "  elif analysis_type=='outlier_winsorizer':\n",
        "    df_feat_eng,list_applied_transformers = FeatEngineering_OutlierWinsorizer(df_feat_eng,column)\n",
        "\n",
        "  elif analysis_type=='ordinal_encoder':\n",
        "    df_feat_eng,list_applied_transformers = FeatEngineering_CategoricalEncoder(df_feat_eng,column)\n",
        "\n",
        "  return df_feat_eng,list_applied_transformers\n",
        "\n",
        "\n",
        "\n",
        "def transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng):\n",
        "  # For each variable, assess how the transformations perform\n",
        "  print(f\"* Variable Analyzed: {column}\")\n",
        "  print(f\"* Applied transformation: {list_applied_transformers} \\n\")\n",
        "  for col in [column] + list_applied_transformers:\n",
        "    \n",
        "    if analysis_type!='ordinal_encoder':\n",
        "      DiagnosticPlots_Numerical(df_feat_eng, col)\n",
        "    \n",
        "    else:\n",
        "      if col == column: \n",
        "        DiagnosticPlots_Categories(df_feat_eng, col)\n",
        "      else:\n",
        "        DiagnosticPlots_Numerical(df_feat_eng, col)\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "def DiagnosticPlots_Categories(df_feat_eng, col):\n",
        "  plt.figure(figsize=(4, 3))\n",
        "  sns.countplot(data=df_feat_eng, x=col,palette=['#432371'],order = df_feat_eng[col].value_counts().index)\n",
        "  plt.xticks(rotation=90) \n",
        "  plt.suptitle(f\"{col}\", fontsize=30,y=1.05)        \n",
        "  plt.show()\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "def DiagnosticPlots_Numerical(df, variable):\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(8, 3))\n",
        "  sns.histplot(data=df, x=variable, kde=True,element=\"step\",ax=axes[0]) \n",
        "  stats.probplot(df[variable], dist=\"norm\", plot=axes[1])\n",
        "  sns.boxplot(x=df[variable],ax=axes[2])\n",
        "  \n",
        "  axes[0].set_title('Histogram')\n",
        "  axes[1].set_title('QQ Plot')\n",
        "  axes[2].set_title('Boxplot')\n",
        "  fig.suptitle(f\"{variable}\", fontsize=30,y=1.05)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def FeatEngineering_CategoricalEncoder(df_feat_eng,column):\n",
        "  list_methods_worked = []\n",
        "  try:  \n",
        "    encoder= OrdinalEncoder(encoding_method='arbitrary', variables = [f\"{column}_ordinal_encoder\"])\n",
        "    df_feat_eng = encoder.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_ordinal_encoder\")\n",
        "  \n",
        "  except: \n",
        "    df_feat_eng.drop([f\"{column}_ordinal_encoder\"],axis=1,inplace=True)\n",
        "    \n",
        "  return df_feat_eng,list_methods_worked\n",
        "\n",
        "\n",
        "def FeatEngineering_OutlierWinsorizer(df_feat_eng,column):\n",
        "  list_methods_worked = []\n",
        "\n",
        "  ### Winsorizer iqr\n",
        "  try: \n",
        "    disc=Winsorizer(\n",
        "        capping_method='iqr', tail='both', fold=1.5, variables = [f\"{column}_iqr\"])\n",
        "    df_feat_eng = disc.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_iqr\")\n",
        "  except: \n",
        "    df_feat_eng.drop([f\"{column}_iqr\"],axis=1,inplace=True)\n",
        "\n",
        "\n",
        "  return df_feat_eng,list_methods_worked\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def FeatEngineering_Numerical(df_feat_eng,column):\n",
        "\n",
        "  list_methods_worked = []\n",
        "\n",
        "  ### LogTransformer base e\n",
        "  try: \n",
        "    lt = vt.LogTransformer(variables = [f\"{column}_log_e\"])\n",
        "    df_feat_eng = lt.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_log_e\")\n",
        "  except: \n",
        "    df_feat_eng.drop([f\"{column}_log_e\"],axis=1,inplace=True)\n",
        "\n",
        "    ### LogTransformer base 10\n",
        "  try: \n",
        "    lt = vt.LogTransformer(variables = [f\"{column}_log_10\"],base='10')\n",
        "    df_feat_eng = lt.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_log_10\")\n",
        "  except: \n",
        "    df_feat_eng.drop([f\"{column}_log_10\"],axis=1,inplace=True)\n",
        "\n",
        "  ### ReciprocalTransformer\n",
        "  try:\n",
        "    rt = vt.ReciprocalTransformer(variables = [f\"{column}_reciprocal\"])\n",
        "    df_feat_eng =  rt.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_reciprocal\")\n",
        "  except:\n",
        "    df_feat_eng.drop([f\"{column}_reciprocal\"],axis=1,inplace=True)\n",
        "\n",
        "  ### PowerTransformer\n",
        "  try:\n",
        "    pt = vt.PowerTransformer(variables = [f\"{column}_power\"])\n",
        "    df_feat_eng = pt.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_power\")\n",
        "  except:\n",
        "    df_feat_eng.drop([f\"{column}_power\"],axis=1,inplace=True)\n",
        "\n",
        "  ### BoxCoxTransformer\n",
        "  try:\n",
        "    bct = vt.BoxCoxTransformer(variables = [f\"{column}_box_cox\"])\n",
        "    df_feat_eng = bct.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_box_cox\")\n",
        "  except:\n",
        "    df_feat_eng.drop([f\"{column}_box_cox\"],axis=1,inplace=True)\n",
        "\n",
        "\n",
        "  ### YeoJohnsonTransformer\n",
        "  try:\n",
        "    yjt = vt.YeoJohnsonTransformer(variables = [f\"{column}_yeo_johnson\"])\n",
        "    df_feat_eng = yjt.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_yeo_johnson\")\n",
        "  except:\n",
        "        df_feat_eng.drop([f\"{column}_yeo_johnson\"],axis=1,inplace=True)\n",
        "\n",
        "\n",
        "  return df_feat_eng,list_methods_worked\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "masShIoqzf2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering Spreadsheet Summary"
      ],
      "metadata": {
        "id": "9yh2FMDd4wWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Consider the notes taken in your spreadsheet summary. List the transformers you will use\n",
        "    * Categorical Encoding\n",
        "    * Numerical Transformation\n",
        "    * Smart Correlation Selection"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REMINDER**\n",
        "  * The transformers decided in this notebook will serve as base to construct the **ML Pipeline** for the upcoming notebooks!"
      ],
      "metadata": {
        "id": "TUsyE39kjWrI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dealing with Feature Engineering"
      ],
      "metadata": {
        "id": "h-9iRH_ZEMoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Categorical Enconding - Ordinal: replaces categories by ordinal numbers "
      ],
      "metadata": {
        "id": "5GT8e9W_onJj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step 1: Select variable(s)"
      ],
      "metadata": {
        "id": "OwG_KMpOonJu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "variables_engineering= ['gender', 'Partner', 'Dependents',\n",
        "                        'PhoneService', 'MultipleLines', 'InternetService',\n",
        "                        'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
        "                        'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
        "                        'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
        "\n",
        "variables_engineering"
      ],
      "outputs": [],
      "metadata": {
        "id": "-Ii9nXtJonJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step 2: Create a separate dataframe, with your variable(s)"
      ],
      "metadata": {
        "id": "t32melBMonJy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_engineering = TrainSet[variables_engineering].copy()\n",
        "df_engineering.head(3)"
      ],
      "outputs": [],
      "metadata": {
        "id": "iJJBWQlconJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step 3: Create engineered variables(s) applying the transformation(s), assess engineered variables distribution and select most suitable method for each variable"
      ],
      "metadata": {
        "id": "_mk058LZonJz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_engineering = FeatureEngineeringAnalysis(df=df_engineering, analysis_type='ordinal_encoder')"
      ],
      "outputs": [],
      "metadata": {
        "id": "vKEuWXrtonJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* For each variable, write you conclusion on how the transformation(s) look(s) to be effective\n",
        "  * For all variables, the transformation is effective, since converted categories to numbers.\n",
        "\n"
      ],
      "metadata": {
        "id": "BfAiPd8DonJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step 4 - Apply the selected transformation to the Train and Test set"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# the steps are: \n",
        "# 1 - create transformer\n",
        "# 2 - fit_transform into TrainSet\n",
        "# 3 - transform into TestSet \n",
        "encoder = OrdinalEncoder(encoding_method='arbitrary', variables = variables_engineering)\n",
        "TrainSet = encoder.fit_transform(TrainSet)\n",
        "TestSet = encoder.transform(TestSet)\n",
        "\n",
        "print(\"* Categorical encoding - ordinal transformation done!\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numerical Transformation"
      ],
      "metadata": {
        "id": "TkyO7KsuyG5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step 1: Select variable(s)"
      ],
      "metadata": {
        "id": "9l4eVnHNyG5E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "variables_engineering = ['tenure','MonthlyCharges']\n",
        "variables_engineering"
      ],
      "outputs": [],
      "metadata": {
        "id": "v-dEF_P4yG5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step 2: Create a separate dataframe, with your variable(s)"
      ],
      "metadata": {
        "id": "kUA_uA1_yG5I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_engineering = TrainSet[variables_engineering].copy()\n",
        "df_engineering.head(3)"
      ],
      "outputs": [],
      "metadata": {
        "id": "xrplTb39yG5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step 3: Create engineered variables(s) applying the transformation(s), assess engineered variables distribution and select most suitable method"
      ],
      "metadata": {
        "id": "QQqqdvd3yG5J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_engineering = FeatureEngineeringAnalysis(df=df_engineering, analysis_type='numerical')"
      ],
      "outputs": [],
      "metadata": {
        "id": "YZXMUZgEyG5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* For each variable, write you conclusion on how the transformation(s) look(s) to be effective\n",
        "  * For all variables - it didn't improved the boxplot distribution or qq plot\n"
      ],
      "metadata": {
        "id": "W5TyFpY1yG5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step 4 - Apply the selected transformation to the Train and Test set"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# we are not applying any numerical transformation to the data"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SmartCorrelatedSelection Variables"
      ],
      "metadata": {
        "id": "g_kMYDKU2yuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step 1: Select variable(s)"
      ],
      "metadata": {
        "id": "Fo7iQbNn2yuX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# for this transformer, you don't need to select variables, since you need all variables for this transformer"
      ],
      "outputs": [],
      "metadata": {
        "id": "FqF5Z5TGrGXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step 2: Create a separate dataframe, with your variable(s)"
      ],
      "metadata": {
        "id": "9-pse1Ge2yub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_engineering = TrainSet.copy()\n",
        "df_engineering.head(3)"
      ],
      "outputs": [],
      "metadata": {
        "id": "2hnHWkNf2yub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step 3: Create engineered variables(s) applying the transformation(s)"
      ],
      "metadata": {
        "id": "CJsN5KNe2yuc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "corr_sel = SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.6,selection_method=\"variance\")\n",
        "\n",
        "corr_sel.fit_transform(df_engineering)\n",
        "corr_sel.correlated_feature_sets_"
      ],
      "outputs": [],
      "metadata": {
        "id": "Vq-jWVT2e2v3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "corr_sel.features_to_drop_"
      ],
      "outputs": [],
      "metadata": {
        "id": "kVQW3s0QfasQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "yZiCdjylhGP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# So what is the conclusion? :)\n"
      ],
      "metadata": {
        "id": "LQSUo5fxnozU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The list below shows the transformations needed for feature engineering.\n",
        "  * You will add these steps into the ML Pipeline"
      ],
      "metadata": {
        "id": "yOP2pVnJnwxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Feature Engineering Transformers\n",
        "  * Ordinal categorical encoding: `['gender', 'Partner', Dependents', 'PhoneService','MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup','DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies','Contract', 'PaperlessBilling', 'PaymentMethod']`\n",
        "  * Smart Correlation Selection: `['OnlineSecurity', 'DeviceProtection', 'TechSupport']`\n",
        "  "
      ],
      "metadata": {
        "id": "O9EtvPIPnpYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Well done! Clear the outputs, and move on to the next notebooks"
      ],
      "metadata": {}
    }
  ]
}